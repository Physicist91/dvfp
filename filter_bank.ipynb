{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"Deep Vision\" architecture\n",
    "\n",
    "![title](img/arch-simplified.png)\n",
    "\n",
    "<img src=\"img/side-branch.png\" alt=\"drawing\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# begin by importing our \"Deep Vision\" module (or dv in short)\n",
    "import dv\n",
    "from dv.model import DeepVision_VGG16\n",
    "from dv.ImageFolder import CarsDataset\n",
    "import dv.helpers as helpers\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from PIL import Image, ImageOps\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paper use input size of 448 x 448, we will use random crop to this size\n",
    "\n",
    "def transform_train():\n",
    "    transform_list = []\n",
    "    transform_list.append(torchvision.transforms.Lambda(lambda x:helpers.rescale(x, 448)))\n",
    "    transform_list.append(torchvision.transforms.RandomHorizontalFlip(p=0.3))\n",
    "    transform_list.append(torchvision.transforms.RandomCrop((448, 448)))\n",
    "    transform_list.append(torchvision.transforms.ToTensor())\n",
    "    transform_list.append(torchvision.transforms.Normalize(mean=(0.5,0.5,0.5),std=(0.5,0.5,0.5)))\n",
    "    return torchvision.transforms.Compose(transform_list)\n",
    "\n",
    "def transform_test():\n",
    "    transform_list = []\n",
    "    transform_list.append(torchvision.transforms.Lambda(lambda x:helpers.rescale(x, 560)))\n",
    "    transform_list.append(torchvision.transforms.TenCrop(448)) \n",
    "    transform_list.append(torchvision.transforms.Lambda(lambda crops: torch.stack([transforms.Normalize(mean=(0.5,0.5,0.5),std=(0.5,0.5,0.5))((transforms.ToTensor())(crop)) for crop in crops])) )\n",
    "    return torchvision.transforms.Compose(transform_list)\n",
    "\n",
    "def transform_test_simple():\n",
    "    transform_list = []\n",
    "    transform_list.append(torchvision.transforms.Lambda(lambda x:helpers.rescale(x, 448)))\n",
    "    transform_list.append(torchvision.transforms.CenterCrop((448, 448)))\n",
    "    transform_list.append(torchvision.transforms.ToTensor())\n",
    "    transform_list.append(torchvision.transforms.Normalize(mean=(0.5,0.5,0.5),std=(0.5,0.5,0.5)))\n",
    "    return torchvision.transforms.Compose(transform_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr0 = 0.1 #initial learning rate\n",
    "momentum = 0.9\n",
    "weight_decay = 0.000005\n",
    "net = DeepVision_VGG16(k = 10, M = 200)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=lr0, momentum=momentum, weight_decay = weight_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset is from https://ai.stanford.edu/~jkrause/cars/car_dataset.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: 8144\n",
      "test size: 8041\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "\n",
    "img_dir = '/Users/kevinsiswandi/dvfp/data'\n",
    "train_dataset = CarsDataset(os.path.join(img_dir,'devkit/cars_train_annos.mat'),\n",
    "                            os.path.join(img_dir,'cars_train'),\n",
    "                            os.path.join(img_dir,'devkit/cars_meta.mat'),\n",
    "                            transform=transform_train()\n",
    "                            )\n",
    "\n",
    "test_dataset = CarsDataset(os.path.join(img_dir,'devkit/cars_test_annos_withlabels.mat'),\n",
    "                            os.path.join(img_dir,'cars_test'),\n",
    "                            os.path.join(img_dir,'devkit/cars_meta.mat'),\n",
    "                            transform=transform_test()\n",
    "                            )\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64,\n",
    "                            shuffle=True, num_workers=1)\n",
    "print(\"train size:\", len(train_dataset))\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=64,\n",
    "                            shuffle=True, num_workers=1)\n",
    "print(\"test size:\", len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'running_loss_g' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-1ec5837fc05d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrunning_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Fuck loss blows up!\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mrunning_loss_g\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss_g\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mrunning_loss_p\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss_p\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mrunning_loss_s\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss_s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'running_loss_g' is not defined"
     ]
    }
   ],
   "source": [
    "# training\n",
    "\n",
    "for epoch in range(5):\n",
    "    lr = lr0 * 0.9 ** (epoch//10) #decay the learning rate every 10 epochs\n",
    "    for group in optimizer.param_groups:\n",
    "        group['lr'] = lr\n",
    "    net.train()\n",
    "    \n",
    "    running_loss = 0\n",
    "    correct_top1 = 0\n",
    "    correct_top5 = 0\n",
    "    checkpoints = 2000 #for printing loss\n",
    "    \n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs, labels = data\n",
    "        labels = labels.type(torch.LongTensor)\n",
    "        \n",
    "        # forward pass\n",
    "        out_g, out_p, out_s, _ = net(inputs)\n",
    "\n",
    "        loss_g = criterion(out_g, labels)\n",
    "        loss_p = criterion(out_p, labels)\n",
    "        loss_s = criterion(out_s, labels)\n",
    "        \n",
    "        loss = 1.0 * loss_g + 1.0 * loss_p + 0.1 * loss_s # the weights for each stream as in the paper\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        assert not np.isnan(running_loss), \"Fuck loss blows up!\"\n",
    "        \n",
    "        running_loss_g += loss_g.item()\n",
    "        running_loss_p += loss_p.item()\n",
    "        running_loss_s += loss_s.item()\n",
    "        \n",
    "        out = 1.0 * out_g + 1.0 * out_p + 0.1 * out_s \n",
    "        top1, top5 = dv.helpers.get_accuracy(out, labels, topk=(1, 5))  # paper cited only top-1\n",
    "        \n",
    "        correct_top1 += top1\n",
    "        correct_top5 += top5\n",
    "        \n",
    "        # backward pass + optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i % checkpoints: # size of data is around 8000 in total\n",
    "            print('Train epoch: {}, {}, {} || Loss: {:.4f} ||\\n'\n",
    "            'Loss G-Stream: {:.4f} || Loss P-Stream: {:.4f} || Loss side branch : {.4f} ||\\n'\n",
    "            'Top-1 Acc: {:.2f} || Top-5 Acc: {:.2f} %%'.format(\n",
    "            epoch, i, len(train_loader), running_loss/checkpoints, running_loss_g/checkpoints, running_loss_p/checkpoints, running_loss_s/checkpoints, correct_top1, correct_top5))\n",
    "            \n",
    "            losses = np.array([running_loss, running_loss_g, running_loss_p, running_loss_s])/checkpoints\n",
    "            \n",
    "            # reset the loss and accuracy at every checkpoints\n",
    "            running_loss = 0\n",
    "            running_loss_g = 0\n",
    "            running_loss_p = 0\n",
    "            running_loss_s = 0\n",
    "            \n",
    "            save_train_info(epoch, i, len(train_loader), losses, correct_top1, correct_top5)\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
