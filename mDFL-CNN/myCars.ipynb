{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dv.transform import *\n",
    "from dv.MyImageFolderWithPaths import CarsDataset\n",
    "import torch\n",
    "import os\n",
    "\n",
    "img_dir = '/Users/kevinsiswandi/dvfp/mDFL-CNN/dataset'\n",
    "\n",
    "transform_sample = get_transform_for_test_simple()\n",
    "sample_dataset = CarsDataset(os.path.join(img_dir,'devkit/cars_train_annos.mat'),\n",
    "                                    os.path.join(img_dir,'cars_train'),\n",
    "                                    os.path.join(img_dir,'devkit/cars_meta.mat'),\n",
    "                                    transform=transform_sample\n",
    "                                    )\n",
    "sample_loader = torch.utils.data.DataLoader(\n",
    "                sample_dataset, batch_size=1, shuffle=True, # use batch_size = 1 please\n",
    "                num_workers=1, pin_memory=True, drop_last = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_patch(val_loader, model, n_channels):\n",
    "    \"\"\"\n",
    "    Initialization for the patch detectors\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    labels_set = set()\n",
    "\n",
    "    for batches in val_loader:\n",
    "        data, target = batches\n",
    "        if target[0] in labels_set:\n",
    "            continue\n",
    "        else:\n",
    "            labels_set.add(target[0])\n",
    "            idx = target[0]\n",
    "\n",
    "        result = torch.zeros(n_channels, model.k * model.nclass)\n",
    "        for j, d in enumerate(data):  # data [batchsize, 3, 448, 448]\n",
    "            d = d.unsqueeze(0) # d [1, 3, 448, 448]\n",
    "            center = model(d)\n",
    "            result[:, idx*model.k : idx*model.k + model.k] = center\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dv.DFL import Energy_ResNet50\n",
    "\n",
    "energyNet = Energy_ResNet50(k = 4) # for non-random initialization\n",
    "center = init_patch(sample_loader, energyNet, 1024) #1024 channels in the feature map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "labels_set = set()\n",
    "for i, d in enumerate(sample_loader):\n",
    "    data, target = d\n",
    "    labels_set.add(target.item())\n",
    "    if(i > 197):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Peek into the dataset\n",
    "* https://www.kaggle.com/eduardo4jesus/stanford-cars-dataset-a-quick-look-up\n",
    "* https://www.kaggle.com/jutrera/training-a-densenet-for-the-stanford-car-dataset\n",
    "\n",
    "Make sure you:\n",
    "1. Load the dataset correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: check against https://github.com/johntd54/stanford_car\n",
    "from dv.MyImageFolderWithPaths import *\n",
    "from utils.transform import *\n",
    "\n",
    "img_dir = '/Users/kevinsiswandi/dvfp/mDFL-CNN/dataset'\n",
    "# transformations are defined in \"dv\" module\n",
    "transform_train = get_transform_for_train()\n",
    "transform_test  = get_transform_for_test()\n",
    "transform_test_simple = get_transform_for_test_simple()\n",
    "\n",
    "train_dataset = CarsDataset(os.path.join(img_dir,'devkit/cars_train_annos.mat'),\n",
    "                        os.path.join(img_dir,'cars_train'),\n",
    "                        os.path.join(img_dir,'devkit/cars_meta.mat'),\n",
    "                        transform=transform_train\n",
    "                        )\n",
    "\n",
    "test_dataset = CarsDataset(os.path.join(img_dir,'devkit/cars_test_annos_withlabels.mat'),\n",
    "                        os.path.join(img_dir,'cars_test'),\n",
    "                        os.path.join(img_dir,'devkit/cars_meta.mat'),\n",
    "                        transform=transform_test\n",
    "                        )\n",
    "\n",
    "test_dataset_simple = CarsDataset(os.path.join(img_dir,'devkit/cars_test_annos_withlabels.mat'),\n",
    "                        os.path.join(img_dir,'cars_test'),\n",
    "                        os.path.join(img_dir,'devkit/cars_meta.mat'),\n",
    "                        transform=transform_test_simple\n",
    "                        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_dataset.car_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = set()\n",
    "for i in range(train_dataset.__len__()):\n",
    "    lst.add(train_dataset.car_annotations[i][-2][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
